{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAnalisys.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioCarlesso/ds-study-codes/blob/main/Codes/pos/TextAnalisys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdsYp105VAXm"
      },
      "source": [
        "TEXT ANALISYS\n",
        "\n",
        "ATIVIDADE INICIAL DE AULA\n",
        "\n",
        "Selecione uma notícia completa, copie-a e salve-a em um arquivo de texto. Utilize a notícia baixada e crie um script que realize o que se pede:\n",
        "- Contar o número de palavras no texto\n",
        "- Imprimir as 10 palavras mais utilizadas\n",
        "- Imprimir os 10 bigramas mais utilizadas\n",
        "- Contar o número de sentenças no texto\n",
        "- Realizar a classificação gramatical (POS e NER) do primeiro parágrafo de te\n",
        "xto, exceto títulos e subtítulo\n",
        "\n",
        "Tempo estimado: 60 minutos\n",
        "\n",
        "Execução em equipe\n",
        "\n",
        "Entrega: Imediata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gRla3JY7jh",
        "outputId": "ed1e7d73-071d-44d4-f78e-610285133130"
      },
      "source": [
        "#Programa para leitura de documentos (DOCx)\n",
        "!pip install python-docx \n",
        "import docx, nltk\n",
        "# Análise de frequência no corpus WebText\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from nltk.corpus import machado\n",
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import CategorizedPlaintextCorpusReader\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=4be1a776648f8ee38627ce9ea2a856658de2bfc56e8c1b56cf4d701ca99e3243\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyCpPkgxUdhk",
        "outputId": "b560bb75-75d9-4fd9-fb2f-432705f5683c"
      },
      "source": [
        "#link da noticia -> https://www.radioculturafoz.com.br/2021/03/05/apoio-de-itaipu-e-fundamental-na-execucao-do-plano-de-contingencia-da-fronteira-diz-chico-brasileiro/\n",
        "#Contar o número de palavras no texto\n",
        "arquivo = '/content/noticia_chico.docx'\n",
        "\n",
        "doc = docx.Document(arquivo)\n",
        "texto_completo = [] #Lista para receber o texto\n",
        "for paragrafo in doc.paragraphs:\n",
        "    texto_completo.append(paragrafo.text)\n",
        "\n",
        "#print(texto_completo)#imprime a lista\n",
        "texto_completo_espaco = ' '.join(texto_completo)\n",
        "#print(texto_completo_espaco)\n",
        "\n",
        "stopwords_pt = stopwords.words('portuguese')\n",
        "tokens = tokenize.word_tokenize(texto_completo_espaco.lower())\n",
        "#print(tokens)\n",
        "minha_stop_w = [',', '.', '\\'', '/', '-', '..', '!', '[', ']', '?', ':', '%', '&', '*', '#', '...', '\\x97', ';', '.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................', '$', '”', '.','r', '“']\n",
        "texto_limpo = []\n",
        "for p in tokens:\n",
        "  if (p not in stopwords_pt) and (p not in minha_stop_w):\n",
        "    texto_limpo.append(p)\n",
        "print(texto_limpo)\n",
        "print('Total de palavras: ', len(texto_limpo))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prefeito', 'chico', 'brasileiro', 'disse', 'nesta', 'quinta-feira', '4', 'repasse', '15', 'milhões', 'itaipu', 'binacional', 'fundação', 'municipal', 'saúde', 'foz', 'iguaçu', 'além', 'parceria', 'várias', 'áreas', 'significa', 'binacional', 'acatou', 'plano', 'contingência', 'elaborado', 'município', 'estado', 'ministério', 'saúde', 'autoridades', 'paraguaias', 'função', 'reabertura', 'ponte', 'amizade', 'setembro', '2020', 'plano', 'prevê', 'ampliação', 'número', 'leitos', 'reorganização', 'interna', 'hospital', 'municipal', 'transferindo', 'alguns', 'setores', 'atendem', 'covid', 'outros', 'hospitais', 'possibilitando', 'número', 'ampliação', 'leitos', 'hospital', 'municipal', 'viabilizar', 'atendimento', 'paciente', 'covid', 'disse', 'chico', 'brasileiro', 'entrevista', 'imprensa', 'chico', 'brasileiro', 'reafirmou', 'itaipu', 'dessa', 'forma', 'amplia', 'reforço', 'habilitação', 'novos', 'leitos', 'novos', 'hoje', 'possível', 'esperar', 'novos', 'leitos', 'porque', 'habilitados', 'paga', 'conta', 'recursos', 'vem', 'ministério', 'saúde', 'município', 'segundo', 'prefeito', 'pagar', '100', 'abrir', 'leitos', 'uti', 'abrimos', '10', 'leitos', 'semana', 'passada', 'vamos', 'instalar', '10', 'leitos', 'nesta', 'semana', 'trata', 'abrir', 'leitos', 'leitos', 'existe', 'capacidade', 'operacional', 'contratar', 'pessoal', 'importante', 'medidas', 'restrição', 'circulação', 'pessoas', 'prefeito', 'adianta', 'atualmente', 'habilitados', '40', 'leitos', 'ministério', 'saúde', 'outros', 'leitos', 'clínicos', 'quais', 'transferência', 'recursos', 'estado', 'torno', '300', 'leito', 'enfermaria', 'muitas', 'vezes', 'transformar', 'leitos', 'enfermaria', 'leitos', 'uti', '30', 'leitos', 'habilitados', 'hoje', 'hospital', 'municipal', 'conta', '70', 'leitos', 'uti']\n",
            "Total de palavras:  164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IedTsircdbiF",
        "outputId": "c67b6cc2-f681-4298-fbd0-d87dbe9eb02b"
      },
      "source": [
        "# Imprimir as 10 palavras mais utilizadas\n",
        "\n",
        "freqDist = nltk.FreqDist(texto_limpo)\n",
        "print(freqDist.most_common(10))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('leitos', 15), ('municipal', 4), ('saúde', 4), ('prefeito', 3), ('chico', 3), ('brasileiro', 3), ('ministério', 3), ('hospital', 3), ('novos', 3), ('habilitados', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4N5qCPbd59s",
        "outputId": "0bdbd1ce-4d55-4bb5-834c-ca863f8f3ef4"
      },
      "source": [
        "# Imprimir os 10 bigramas mais comuns\n",
        "\n",
        "bigramas = []\n",
        "for ng in ngrams(texto_limpo, 2):\n",
        "        bigramas.append(ng)\n",
        "\n",
        "freq_bigramas = nltk.FreqDist(bigramas)\n",
        "print(freq_bigramas.most_common(10))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('chico', 'brasileiro'), 3), (('ministério', 'saúde'), 3), (('hospital', 'municipal'), 3), (('leitos', 'uti'), 3), (('novos', 'leitos'), 2), (('abrir', 'leitos'), 2), (('10', 'leitos'), 2), (('prefeito', 'chico'), 1), (('brasileiro', 'disse'), 1), (('disse', 'nesta'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhR60QdCeMU7",
        "outputId": "2f587754-babd-4efd-d3dd-c4731f2fe2fd"
      },
      "source": [
        "# Contar o número de sentenças no texto\n",
        "\n",
        "palavras_s = sent_tokenize(texto_completo_espaco)\n",
        "sentencas = []\n",
        "for s in palavras_s:\n",
        "  sentencas.append(s)\n",
        "  # print(s)\n",
        "\n",
        "print(sentencas)\n",
        "print('Total de sentenças: ', len(sentencas))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O prefeito Chico Brasileiro disse nesta quinta-feira, 4, que o repasse de R$ 15 milhões da Itaipu Binacional à Fundação Municipal de Saúde de Foz do Iguaçu, além da parceria em várias áreas, significa também que a binacional acatou o plano de contingência elaborado pelo Município, Estado, Ministério da Saúde e autoridades paraguaias em função da reabertura da Ponte da Amizade em setembro de 2020.', '“O plano prevê a ampliação do número de leitos, a reorganização interna do hospital municipal, transferindo alguns setores que não atendem covid para outros hospitais e possibilitando número a ampliação de leitos do hospital municipal para viabilizar o atendimento paciente com covid”, disse Chico Brasileiro em entrevista à imprensa.', 'Chico Brasileiro reafirmou que a Itaipu, dessa forma, amplia o reforço na habilitação de novos leitos novos e que hoje não é possível mais esperar por novos leitos, “até porque mesmo habilitados, não se paga a conta com os recursos que vem do Ministério da Saúde”  O Município, segundo o prefeito, tem que pagar mais de 100% para abrir leitos de UTI.', '“Já abrimos mais 10 leitos semana passada e vamos instalar mais 10 leitos nesta semana”.', '“Não se trata de abrir leitos e leitos, não existe mais capacidade operacional nem como contratar pessoal.', 'Por isso é importante as medidas de restrição de circulação de pessoas”.', 'O prefeito adianta que, atualmente, estão habilitados 40 leitos no Ministério da Saúde e “outros leitos clínicos”, dos quais há transferência de recursos do Estado em torno de R$ 300 por leito de enfermaria.', '“Só que muitas vezes, temos que transformar leitos de enfermaria em leitos de UTI.', 'São 30 leitos a mais que não estão habilitados e hoje o Hospital Municipal conta com 70 leitos de UTI”.']\n",
            "Total de sentenças:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2VtZFDslDyr",
        "outputId": "7b970fc5-aff7-4f45-8ac4-35ced4678101"
      },
      "source": [
        "# Realizar a classificação gramatical (POS e NER) do primeiro parágrafo de texto, exceto títulos e subtítulo\n",
        "\n",
        "palavras_p = word_tokenize(texto_completo[0])\n",
        "print(palavras_p)\n",
        "print('### POS ###')\n",
        "pos_tags = nltk.pos_tag(palavras_p)\n",
        "for p in pos_tags:\n",
        "  print(p)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'prefeito', 'Chico', 'Brasileiro', 'disse', 'nesta', 'quinta-feira', ',', '4', ',', 'que', 'o', 'repasse', 'de', 'R', '$', '15', 'milhões', 'da', 'Itaipu', 'Binacional', 'à', 'Fundação', 'Municipal', 'de', 'Saúde', 'de', 'Foz', 'do', 'Iguaçu', ',', 'além', 'da', 'parceria', 'em', 'várias', 'áreas', ',', 'significa', 'também', 'que', 'a', 'binacional', 'acatou', 'o', 'plano', 'de', 'contingência', 'elaborado', 'pelo', 'Município', ',', 'Estado', ',', 'Ministério', 'da', 'Saúde', 'e', 'autoridades', 'paraguaias', 'em', 'função', 'da', 'reabertura', 'da', 'Ponte', 'da', 'Amizade', 'em', 'setembro', 'de', '2020', '.']\n",
            "### POS ###\n",
            "('O', 'NNP')\n",
            "('prefeito', 'NN')\n",
            "('Chico', 'NNP')\n",
            "('Brasileiro', 'NNP')\n",
            "('disse', 'NN')\n",
            "('nesta', 'JJ')\n",
            "('quinta-feira', 'JJ')\n",
            "(',', ',')\n",
            "('4', 'CD')\n",
            "(',', ',')\n",
            "('que', 'NN')\n",
            "('o', 'FW')\n",
            "('repasse', 'NN')\n",
            "('de', 'FW')\n",
            "('R', 'NNP')\n",
            "('$', '$')\n",
            "('15', 'CD')\n",
            "('milhões', 'NN')\n",
            "('da', 'NN')\n",
            "('Itaipu', 'NNP')\n",
            "('Binacional', 'NNP')\n",
            "('à', 'NNP')\n",
            "('Fundação', 'NNP')\n",
            "('Municipal', 'NNP')\n",
            "('de', 'FW')\n",
            "('Saúde', 'NNP')\n",
            "('de', 'FW')\n",
            "('Foz', 'NNP')\n",
            "('do', 'VBP')\n",
            "('Iguaçu', 'NNP')\n",
            "(',', ',')\n",
            "('além', 'NN')\n",
            "('da', 'NN')\n",
            "('parceria', 'NN')\n",
            "('em', 'NN')\n",
            "('várias', 'NN')\n",
            "('áreas', 'NNP')\n",
            "(',', ',')\n",
            "('significa', 'NN')\n",
            "('também', 'NN')\n",
            "('que', 'NN')\n",
            "('a', 'DT')\n",
            "('binacional', 'JJ')\n",
            "('acatou', 'NN')\n",
            "('o', 'JJ')\n",
            "('plano', 'NN')\n",
            "('de', 'IN')\n",
            "('contingência', 'FW')\n",
            "('elaborado', 'FW')\n",
            "('pelo', 'NN')\n",
            "('Município', 'NNP')\n",
            "(',', ',')\n",
            "('Estado', 'NNP')\n",
            "(',', ',')\n",
            "('Ministério', 'NNP')\n",
            "('da', 'VBZ')\n",
            "('Saúde', 'NNP')\n",
            "('e', 'NN')\n",
            "('autoridades', 'NNS')\n",
            "('paraguaias', 'VBP')\n",
            "('em', 'JJ')\n",
            "('função', 'NN')\n",
            "('da', 'NN')\n",
            "('reabertura', 'NN')\n",
            "('da', 'NN')\n",
            "('Ponte', 'NNP')\n",
            "('da', 'NN')\n",
            "('Amizade', 'NNP')\n",
            "('em', 'NN')\n",
            "('setembro', 'NN')\n",
            "('de', 'IN')\n",
            "('2020', 'CD')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('### NER ###')\n",
        "chuncks = nltk.ne_chunk(pos_tags, binary=True)\n",
        "for chunck in chuncks:\n",
        "  print(chunck)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTPnG8csLRzW",
        "outputId": "4c71a1dc-0173-403a-fa32-40e8877303c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### NER ###\n",
            "('O', 'NNP')\n",
            "('prefeito', 'NN')\n",
            "(NE Chico/NNP Brasileiro/NNP)\n",
            "('disse', 'NN')\n",
            "('nesta', 'JJ')\n",
            "('quinta-feira', 'JJ')\n",
            "(',', ',')\n",
            "('4', 'CD')\n",
            "(',', ',')\n",
            "('que', 'NN')\n",
            "('o', 'FW')\n",
            "('repasse', 'NN')\n",
            "('de', 'FW')\n",
            "('R', 'NNP')\n",
            "('$', '$')\n",
            "('15', 'CD')\n",
            "('milhões', 'NN')\n",
            "('da', 'NN')\n",
            "(NE Itaipu/NNP Binacional/NNP)\n",
            "('à', 'NNP')\n",
            "('Fundação', 'NNP')\n",
            "('Municipal', 'NNP')\n",
            "('de', 'FW')\n",
            "('Saúde', 'NNP')\n",
            "('de', 'FW')\n",
            "('Foz', 'NNP')\n",
            "('do', 'VBP')\n",
            "(NE Iguaçu/NNP)\n",
            "(',', ',')\n",
            "('além', 'NN')\n",
            "('da', 'NN')\n",
            "('parceria', 'NN')\n",
            "('em', 'NN')\n",
            "('várias', 'NN')\n",
            "('áreas', 'NNP')\n",
            "(',', ',')\n",
            "('significa', 'NN')\n",
            "('também', 'NN')\n",
            "('que', 'NN')\n",
            "('a', 'DT')\n",
            "('binacional', 'JJ')\n",
            "('acatou', 'NN')\n",
            "('o', 'JJ')\n",
            "('plano', 'NN')\n",
            "('de', 'IN')\n",
            "('contingência', 'FW')\n",
            "('elaborado', 'FW')\n",
            "('pelo', 'NN')\n",
            "('Município', 'NNP')\n",
            "(',', ',')\n",
            "(NE Estado/NNP)\n",
            "(',', ',')\n",
            "(NE Ministério/NNP)\n",
            "('da', 'VBZ')\n",
            "(NE Saúde/NNP)\n",
            "('e', 'NN')\n",
            "('autoridades', 'NNS')\n",
            "('paraguaias', 'VBP')\n",
            "('em', 'JJ')\n",
            "('função', 'NN')\n",
            "('da', 'NN')\n",
            "('reabertura', 'NN')\n",
            "('da', 'NN')\n",
            "(NE Ponte/NNP)\n",
            "('da', 'NN')\n",
            "(NE Amizade/NNP)\n",
            "('em', 'NN')\n",
            "('setembro', 'NN')\n",
            "('de', 'IN')\n",
            "('2020', 'CD')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entidades = []\n",
        "rotulos = []\n",
        "\n",
        "for chunck in chuncks:\n",
        "  if hasattr(chunck, 'label'):\n",
        "    entidades.append(' '.join(c[0] for c in chunck))\n",
        "    rotulos.append(chunck.label())\n",
        "\n",
        "print('######')\n",
        "print(entidades)\n",
        "print(rotulos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73eOYP9KLVnT",
        "outputId": "653ef1b5-42bf-4567-c40f-5ea66c8da3d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######\n",
            "['Chico Brasileiro', 'Itaipu Binacional', 'Iguaçu', 'Estado', 'Ministério', 'Saúde', 'Ponte', 'Amizade']\n",
            "['NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE', 'NE']\n"
          ]
        }
      ]
    }
  ]
}