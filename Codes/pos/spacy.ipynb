{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4+KybGU4T3e8SF4Cyisx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabioCarlesso/ds-study-codes/blob/main/Codes/pos/spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCj0r9654Hxw",
        "outputId": "81483f72-24a3-41d8-a4a1-3c7ee384d79c"
      },
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "import pkg_resources, imp\n",
        "imp.reload(pkg_resources)\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBAO3K_C-LLb",
        "outputId": "c6d77dcc-cbc1-47c4-f63d-d181386f0b36"
      },
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "texto = 'Apple adquire Zoom na China na quinta-feira 6 de maio de 2020. Essa notícia fez as ações da Apple e da Google subirem 5% nos Estados Unidos.'\n",
        "doc = nlp(texto)\n",
        "print('Texto: ', doc)\n",
        "print('### nlp pt ###')\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.dep_)\n",
        "\n",
        "print('### Entidade ###')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.start_char, ent.label_)\n",
        "\n",
        "#Atividade rapida\n",
        "#Comparar o POS do NLTK com o Spacy utilizando a frase Apple\n",
        "\n",
        "print('### POS ###')\n",
        "palavras_p = word_tokenize(texto)\n",
        "pos_tags = nltk.pos_tag(palavras_p)\n",
        "for p in pos_tags:\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto:  Apple adquire Zoom na China na quinta-feira 6 de maio de 2020. Essa notícia fez as ações da Apple e da Google subirem 5% nos Estados Unidos.\n",
            "### nlp pt ###\n",
            "Apple PROPN nsubj\n",
            "adquire VERB ROOT\n",
            "Zoom PROPN obj\n",
            "na PROPN flat:name\n",
            "China PROPN flat:name\n",
            "na PROPN flat:name\n",
            "quinta-feira NOUN flat:name\n",
            "6 NUM nummod\n",
            "de ADP case\n",
            "maio NOUN nmod:tmod\n",
            "de ADP case\n",
            "2020 NUM nmod\n",
            ". PUNCT punct\n",
            "Essa DET det\n",
            "notícia NOUN nsubj\n",
            "fez VERB ROOT\n",
            "as DET det\n",
            "ações NOUN obj\n",
            "da ADP case\n",
            "Apple PROPN nmod\n",
            "e CCONJ cc\n",
            "da ADP case\n",
            "Google PROPN conj\n",
            "subirem VERB advcl\n",
            "5 NUM nummod\n",
            "% SYM obj\n",
            "nos PRON obj\n",
            "Estados PROPN obj\n",
            "Unidos PROPN flat:name\n",
            ". PUNCT punct\n",
            "### Entidade ###\n",
            "Apple 0 ORG\n",
            "Zoom 14 MISC\n",
            "China 22 LOC\n",
            "Apple 92 ORG\n",
            "Google 103 ORG\n",
            "Estados Unidos 125 LOC\n",
            "### POS ###\n",
            "('Apple', 'NNP')\n",
            "('adquire', 'NN')\n",
            "('Zoom', 'NNP')\n",
            "('na', 'IN')\n",
            "('China', 'NNP')\n",
            "('na', 'VBD')\n",
            "('quinta-feira', 'JJ')\n",
            "('6', 'CD')\n",
            "('de', 'FW')\n",
            "('maio', 'FW')\n",
            "('de', 'IN')\n",
            "('2020', 'CD')\n",
            "('.', '.')\n",
            "('Essa', 'NNP')\n",
            "('notícia', 'JJ')\n",
            "('fez', 'NN')\n",
            "('as', 'IN')\n",
            "('ações', 'JJ')\n",
            "('da', 'NN')\n",
            "('Apple', 'NNP')\n",
            "('e', 'NN')\n",
            "('da', 'NN')\n",
            "('Google', 'NNP')\n",
            "('subirem', 'VBD')\n",
            "('5', 'CD')\n",
            "('%', 'NN')\n",
            "('nos', 'JJ')\n",
            "('Estados', 'NNP')\n",
            "('Unidos', 'NNP')\n",
            "('.', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}